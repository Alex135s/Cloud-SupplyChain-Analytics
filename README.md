# â˜ï¸ Global Supply Chain Analytics (GCP Pipeline)

## ğŸ“ Sobre el Proyecto
Este proyecto simula un entorno de **IngenierÃ­a de Datos Moderno** para una empresa de logÃ­stica global. El objetivo fue migrar datos locales a la nube, transformarlos y visualizar pÃ©rdidas financieras en tiempo real.

## ğŸ—ï¸ Arquitectura del Pipeline (Tech Stack)
Este proyecto no corre en local, sino en la arquitectura Cloud de Google:
1.  **Python (ETL):** Script de extracciÃ³n y limpieza que normaliza fechas y estandariza nombres de columnas para compatibilidad con BigQuery.
2.  **Google BigQuery (Data Warehouse):** Almacenamiento y procesamiento de datos masivos.
    * *TÃ©cnica:* Uso de Vistas Materializadas y casting de tipos (`SAFE_CAST`) para asegurar integridad de datos.
3.  **Looker Studio (BI):** ConexiÃ³n nativa a la nube para visualizaciÃ³n geoespacial de rentabilidad.

## ğŸ” Hallazgos Clave
* **Productos CrÃ­ticos:** La subcategorÃ­a "Tables" (Mesas) representa la mayor fuga de capital, operando con mÃ¡rgenes negativos.
* **LogÃ­stica:** El tiempo promedio de envÃ­o global es de 4 dÃ­as. El servicio "Standard Class" llega a los 5 dÃ­as, cumpliendo el SLA esperado.
* **GeografÃ­a:** Se detectaron mercados crÃ­ticos en rojo (mapa de calor) que requieren intervenciÃ³n inmediata.

## ğŸ“¸ Dashboard (Looker Studio)
![Dashboard Looker](Dashboard_Looker.png)

---
*Proyecto de IngenierÃ­a de Datos realizado por Geremy Hernandez
